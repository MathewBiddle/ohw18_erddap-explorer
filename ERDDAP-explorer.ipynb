{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERDDAP Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "\n",
    "\n",
    "# server = 'https://erddap-uncabled.oceanobservatories.org/uncabled/erddap'\n",
    "server = 'http://erddap.secoora.org/erddap'\n",
    "e = ERDDAP(server=server, protocol='tabledap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pendulum\n",
    "\n",
    "\n",
    "initial_standard_name = 'sea_surface_height_above_sea_level'\n",
    "\n",
    "cdm_data_type = 'TimeSeries'\n",
    "\n",
    "max_time = pendulum.now(tz='UTC')\n",
    "min_time = max_time.subtract(weeks=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = f'{server}/categorize/standard_name/index.csv'\n",
    "\n",
    "df = pd.read_csv(url, skiprows=[1, 2])\n",
    "\n",
    "# variables = df['Category'].values.tolist()\n",
    "variables = [\n",
    "    'relative_humidity',\n",
    "    'river_discharge',\n",
    "    'sea_surface_height_above_sea_level',\n",
    "    'sea_surface_wave_significant_height',\n",
    "    'sea_surface_wind_wave_significant_height',\n",
    "    'sea_water_ph_reported_on_total_scale',\n",
    "    'sea_water_practical_salinity',\n",
    "    'sea_water_pressure',\n",
    "    'sea_water_temperature',\n",
    "    'solar_radiation',\n",
    "    'water_surface_height_above_reference_datum',\n",
    "    'wind_speed',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "\n",
    "\n",
    "dpdown = ipywidgets.Dropdown(\n",
    "    options=variables,\n",
    "    value=initial_standard_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point(dataset, lon, lat):\n",
    "    geojsonFeature = {\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            'datasetID': dataset,\n",
    "        },\n",
    "        'geometry': {\n",
    "            'type': 'Point',\n",
    "            'coordinates': [lon, lat]\n",
    "        }\n",
    "    };\n",
    "    geojsonFeature['properties']['style'] = {'color': 'Grey'}\n",
    "    return geojsonFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_search(e, standard_name, min_time, max_time):\n",
    "    try:\n",
    "        search_url = e.get_search_url(\n",
    "            response='csv',\n",
    "            cdm_data_type='timeseries',\n",
    "            items_per_page=100000,\n",
    "            standard_name=standard_name,\n",
    "            min_time=min_time,\n",
    "            max_time=max_time\n",
    "        )\n",
    "        df = pd.read_csv(search_url)\n",
    "    except Exception:\n",
    "        df = []\n",
    "        if len(var) > 14:\n",
    "            v = '{}...'.format(standard_name[:15])\n",
    "        else:\n",
    "            v = standard_name\n",
    "        figure.title = f'No {v} found in this time range. Pick another variable.'\n",
    "        figure.marks[0].y = 0.0 * figure.marks[0].y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "\n",
    "def all_positions(e, cdm_data_type, min_time, max_time):\n",
    "    url = (\n",
    "        f'{e.server}/tabledap/allDatasets.csv?'\n",
    "        f'datasetID,minLongitude,minLatitude'\n",
    "        f'&cdm_data_type=\"{cdm_data_type}\"'\n",
    "        f'&minTime<={max_time}'\n",
    "        f'&maxTime>={min_time}'\n",
    "    )\n",
    "    data = io.BytesIO(requests.get(url).content)\n",
    "    df = pd.read_csv(data, skiprows=[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdname2geojson(e, standard_name, min_time, max_time):\n",
    "    search = adv_search(e, standard_name, min_time, max_time)\n",
    "    \n",
    "    if isinstance(search, pd.DataFrame):\n",
    "        datasets = search['Dataset ID'].values\n",
    "        positions = all_positions(e, cdm_data_type, min_time, max_time)\n",
    "        data = positions[positions['datasetID'].isin(search['Dataset ID'])]\n",
    "\n",
    "        geojson = {\n",
    "            'features': [\n",
    "                point(row[1], row[2], row[3]) for row in data.itertuples()\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        geojson = {\n",
    "            'features': []\n",
    "        }\n",
    "        datasets = []\n",
    "    return geojson, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_handler(event=None, id=None, properties=None):\n",
    "    datasetID = properties['datasetID']\n",
    "\n",
    "    kwargs = {\n",
    "        'time>=': min_time,\n",
    "        'time<=': max_time\n",
    "    }\n",
    "\n",
    "    df, var = get_data(datasetID, dpdown.value, kwargs)\n",
    "\n",
    "    figure.marks[0].x = df.index\n",
    "    figure.marks[0].y = df[var]\n",
    "    figure.title = f'{properties[\"datasetID\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import GeoJSON\n",
    "\n",
    "\n",
    "def update_dpdown(change):\n",
    "    standard_name = change['new']\n",
    "    data, datasets = stdname2geojson(e, standard_name, min_time, max_time)\n",
    "    feature_layer = GeoJSON(data=data)\n",
    "    feature_layer.on_click(click_handler)\n",
    "    m.layers = [m.layers[0], feature_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpdown.observe(update_dpdown, names=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_id, standard_name, kwargs):\n",
    "    var = e.get_var_by_attr(\n",
    "        dataset_id=dataset_id,\n",
    "        standard_name=lambda v: str(v).lower() == standard_name)[0]\n",
    "    e.dataset_id = dataset_id\n",
    "    e.variables = ['time', var]\n",
    "    e.constraints = kwargs\n",
    "    df = e.to_pandas(index_col='time', parse_dates=True, skiprows=[1])\n",
    "    return df, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, basemaps\n",
    "\n",
    "\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemaps.Esri.NatGeoWorldMap,\n",
    "    center=[29.67, -80.82],\n",
    "    zoom=5,\n",
    ")\n",
    "\n",
    "\n",
    "data, datasets = stdname2geojson(e, initial_standard_name, min_time, max_time)\n",
    "feature_layer = GeoJSON(data=data)\n",
    "feature_layer.on_click(click_handler)\n",
    "m.layers = [m.layers[0], feature_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bqplot\n",
    "\n",
    "\n",
    "dt_x = bqplot.DateScale()\n",
    "sc_y = bqplot.LinearScale()\n",
    "\n",
    "initial_dataset = datasets[0]\n",
    "kwargs = {'time>=': min_time, 'time<=': max_time}\n",
    "\n",
    "df, var = get_data(initial_dataset, initial_standard_name, kwargs)\n",
    "\n",
    "time_series = bqplot.Lines(x=df.index, y=df[var], scales={'x': dt_x, 'y': sc_y})\n",
    "\n",
    "ax_x = bqplot.Axis(scale=dt_x, label='Time')\n",
    "ax_y = bqplot.Axis(scale=sc_y, orientation='vertical')\n",
    "\n",
    "figure = bqplot.Figure(marks=[time_series], axes=[ax_x, ax_y])\n",
    "figure.title = f'{initial_dataset}'\n",
    "figure.layout.height = '300px'\n",
    "figure.layout.width = '800px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a018da123e6467ea79aa030e3de6b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(index=2, options=('relative_humidity', 'river_discharge', 'sea_surface_height_above_seâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipywidgets.VBox([dpdown, m, figure])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
